{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# UGCrawler 1.0 alpha\n",
    "\n",
    "This Notebook contains code fragments to crawl ultimate-guitar.com. It is far from finished but all the major components are there. \n",
    "\n",
    "Since it is not feasible for me to generate a complete rip, i am sharing this with all the guitarists out there who are pissed off by UG for any of the million reasons given. \n",
    "\n",
    "If you would like to contribute, by doing part of the crawl, of implementin a better selection logic, or in any other way, feel free to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import lxml.html\n",
    "import string\n",
    "import urllib.request\n",
    "from time import sleep\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "chars = ['0-9'] + list(string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_band_urls(char):    \n",
    "    base_url = 'https://www.ultimate-guitar.com/bands/{}.htm'\n",
    "    \n",
    "    htmlparser = etree.HTMLParser()\n",
    "    \n",
    "    band_dict = {}\n",
    "    \n",
    "    cnt = 0\n",
    "    while True:\n",
    "        sleep(random.uniform(.8, 1.2))\n",
    "        \n",
    "        postfix = '' if cnt == 0 else cnt\n",
    "        response = urllib.request.urlopen(base_url.format(char + str(postfix)))\n",
    "        tree = etree.parse(response, htmlparser)\n",
    "\n",
    "        # collect song links\n",
    "        tab_table = tree.xpath('//*[contains(@class, \"b3\")]/../table[2]/tr/td[2]/a')\n",
    "        \n",
    "        # empty means no more pages\n",
    "        if not tab_table:\n",
    "            break\n",
    "            \n",
    "        for child in tab_table:\n",
    "            band_dict[child.text[:-5]] = child.attrib['href']\n",
    "        cnt += 1\n",
    "        \n",
    "    return band_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_artist_links(url):\n",
    "    base_url = 'https://www.ultimate-guitar.com'\n",
    "\n",
    "    url = base_url + url[:-4] + '{}' + url[-4:]\n",
    "    \n",
    "    htmlparser = etree.HTMLParser()\n",
    "    \n",
    "    all_tabs_chords = []\n",
    "    \n",
    "    cnt = 0\n",
    "    tries = 0\n",
    "    while True:\n",
    "        sleep(random.uniform(.8, 1.2))\n",
    "        \n",
    "        # page 0 exists and is pretty much page 1 without the album shit\n",
    "        if cnt == 1:\n",
    "            cnt = 2\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            response = urllib.request.urlopen(url.format(cnt))\n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 404:\n",
    "                # end of tab sites\n",
    "                break\n",
    "            else:\n",
    "                # retry\n",
    "                if tries > 5:\n",
    "                    cnt += 1\n",
    "                    tries = 0\n",
    "                else:\n",
    "                    tries += 1\n",
    "                continue\n",
    "                    \n",
    "        tries = 0\n",
    "        \n",
    "        tree = etree.parse(response, htmlparser)\n",
    "        \n",
    "        # collect entries\n",
    "        tab_table = tree.xpath(\"//td/b[./text()='Tab' or ./text()='tab']/../..\")\n",
    "        chords_table = tree.xpath(\"//td/b[./text()='Chords' or ./text()='chords']/../..\")\n",
    "\n",
    "        for song in tab_table:\n",
    "            name = song.xpath('./td[1]/a[1]')[0].text    \n",
    "            link = song.xpath('./td[1]/a[1]')[0].attrib['href']\n",
    "\n",
    "            if not song.xpath('./td[2]/span[1]'):\n",
    "                rating = 0\n",
    "            else:\n",
    "                rating = song.xpath('./td[2]/span[1]')[0].attrib['title']\n",
    "\n",
    "            all_tabs_chords.append(\n",
    "                {\n",
    "                    'name': name,\n",
    "                    'link': link,\n",
    "                    'rating': float(rating),\n",
    "                    'type': 'tab'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "        for song in chords_table:\n",
    "            name = song.xpath('./td[1]/a[1]')[0].text    \n",
    "            link = song.xpath('./td[1]/a[1]')[0].attrib['href']\n",
    "\n",
    "            if not song.xpath('./td[2]/span[1]'):\n",
    "                rating = 0\n",
    "            else:\n",
    "                rating = song.xpath('./td[2]/span[1]')[0].attrib['title']\n",
    "\n",
    "            all_tabs_chords.append(\n",
    "                {\n",
    "                    'name': name,\n",
    "                    'link': link,\n",
    "                    'rating': float(rating),\n",
    "                    'type': 'chords'\n",
    "                }\n",
    "            )        \n",
    "        cnt += 1\n",
    "        \n",
    "    return all_tabs_chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_print_version(url):\n",
    "    tries = 0\n",
    "    while tries < 5:\n",
    "        try:\n",
    "            response = urllib.request.urlopen(url)\n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 404:\n",
    "                return None\n",
    "            else:\n",
    "                tries += 1\n",
    "                continue\n",
    "                \n",
    "        htmlparser = etree.HTMLParser()\n",
    "        tree = etree.parse(response, htmlparser)\n",
    "        \n",
    "        # get link\n",
    "        link = tree.xpath(\"//*[@id='print_link']\")[0].attrib['href']\n",
    "        response = urllib.request.urlopen('https://tabs.ultimate-guitar.com{}'.format(link))\n",
    "        \n",
    "        ht = lxml.html.parse(response)\n",
    "        return ht.xpath(\"//div[contains(@class, 'tb_ct')]\")[0].text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Here are some examples of how the functions work, and what they return, should be self explanatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "band_urls = get_band_urls('w')\n",
    "band_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "artist_links = get_artist_links('/tabs/we_are_scientists_tabs.htm')\n",
    "artist_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab = get_print_version('https://tabs.ultimate-guitar.com/tab/we_are_scientists/this_scene_is_dead_tabs_844257')\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    return ' '.join(re.sub('[^a-zA-Z0-9\\(\\)\\-\\s\"\\'!?#$\\+]', '', s).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNLEASH THE SPIDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re, os\n",
    "\n",
    "highest_rated_only = True\n",
    "target_dir = '/home/max/ssd_2/UG/'\n",
    "\n",
    "for c in chars:\n",
    "    # rip the band urls\n",
    "    band_urls = get_band_urls(c)\n",
    "    \n",
    "    # rip the tabs for each band\n",
    "    for artist, url in band_urls.items():\n",
    "        \n",
    "        # make out dirs\n",
    "        artist_folder_name = clean(artist)\n",
    "        artist_dir = os.path.join(target_dir, c, artist_folder_name)\n",
    "        \n",
    "        if not os.path.exists(artist_dir):\n",
    "            os.makedirs(artist_dir)\n",
    "            os.makedirs(os.path.join(artist_dir, 'chords'))\n",
    "            os.makedirs(os.path.join(artist_dir, 'tab'))\n",
    "        else:\n",
    "            # assume we finished crawling this artist\n",
    "            continue\n",
    "        \n",
    "        artist_dict = {}\n",
    "        artist_dict['chords'] = {}\n",
    "        artist_dict['tab'] = {}\n",
    "        \n",
    "        # rip\n",
    "        print('Crawling {}...'.format(artist))\n",
    "        song_links = get_artist_links(url)\n",
    "\n",
    "        # keep the highest rated version, factoring in rating count        \n",
    "        for song_dict in song_links:\n",
    "            t = song_dict['type']\n",
    "            \n",
    "            if highest_rated_only:\n",
    "                cleaned_name = clean(song_dict['name'])\n",
    "                \n",
    "                if cleaned_name not in artist_dict[t].keys() \\\n",
    "                or artist_dict[t][cleaned_name]['rating'] < song_dict['rating']:\n",
    "                    artist_dict[t][cleaned_name] = song_dict\n",
    "            else:\n",
    "                artist_dict[t][song_dict['name']] = song_dict                \n",
    "            \n",
    "        # rip and write songs to drive\n",
    "        for name, d in artist_dict['tab'].items():\n",
    "            tab = get_print_version(d['link'])\n",
    "            \n",
    "            file_name = clean(name) + '.txt'\n",
    "            \n",
    "            with open(os.path.join(artist_dir, 'tab', file_name), 'w') as out:\n",
    "                out.write(tab)\n",
    "            \n",
    "            \n",
    "        for name, d in artist_dict['chords'].items():\n",
    "            chords = get_print_version(d['link'])\n",
    "            \n",
    "            file_name = clean(name) + '.txt'\n",
    "            \n",
    "            with open(os.path.join(artist_dir, 'chords', file_name), 'w') as out:\n",
    "                out.write(chords)\n",
    "\n",
    "        \n",
    "\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.uniform(.8, 1.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
