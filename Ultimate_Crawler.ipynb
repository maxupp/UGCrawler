{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UGCrawler 0.8 alpha\n",
    "\n",
    "This Notebook contains code fragments to crawl ultimate-guitar.com. It is far from finished but all the major components are there. \n",
    "\n",
    "Since it is not feasible for me to generate a complete rip, i am sharing this with all the guitarists out there who are pissed off by UG for any of the million reasons given. \n",
    "\n",
    "If you would like to contribute, by doing part of the crawl, of implementin a better selection logic, or in any other way, feel free to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import lxml.html\n",
    "import string\n",
    "import urllib.request\n",
    "from time import sleep\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "chars = ['0-9'] + list(string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_band_urls(char):    \n",
    "    base_url = 'https://www.ultimate-guitar.com/bands/{}.htm'\n",
    "    \n",
    "    htmlparser = etree.HTMLParser()\n",
    "    \n",
    "    band_dict = {}\n",
    "    \n",
    "    cnt = 0\n",
    "    while True:\n",
    "        sleep(0.2)\n",
    "        \n",
    "        postfix = '' if cnt == 0 else cnt\n",
    "        response = urllib.request.urlopen(base_url.format(char + str(postfix)))\n",
    "        tree = etree.parse(response, htmlparser)\n",
    "\n",
    "        # collect song links\n",
    "        tab_table = tree.xpath('//*[contains(@class, \"b3\")]/../table[2]/tr/td[2]/a')\n",
    "        \n",
    "        # empty means no more pages\n",
    "        if not tab_table:\n",
    "            break\n",
    "            \n",
    "        for child in tab_table:\n",
    "            band_dict[child.text[:-5]] = child.attrib['href']\n",
    "        cnt += 1\n",
    "        \n",
    "    return band_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_artist_links(url):\n",
    "    base_url = 'https://www.ultimate-guitar.com'\n",
    "\n",
    "    url = base_url + url[:-4] + '{}' + url[-4:]\n",
    "    \n",
    "    htmlparser = etree.HTMLParser()\n",
    "    \n",
    "    all_tabs_chords = []\n",
    "    \n",
    "    cnt = 0\n",
    "    tries = 0\n",
    "    while True:\n",
    "        sleep(1)\n",
    "        \n",
    "        # page 0 exists and is pretty much page 1 without the album shit\n",
    "        if cnt == 1:\n",
    "            cnt = 2\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            response = urllib.request.urlopen(url.format(cnt))\n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 404:\n",
    "                # end of tab sites\n",
    "                break\n",
    "            else:\n",
    "                # retry\n",
    "                if tries > 5:\n",
    "                    cnt += 1\n",
    "                    tries = 0\n",
    "                else:\n",
    "                    tries += 1\n",
    "                continue\n",
    "                    \n",
    "        tries = 0\n",
    "        \n",
    "        tree = etree.parse(response, htmlparser)\n",
    "        \n",
    "        # collect entries\n",
    "        tab_table = tree.xpath(\"//td/b[./text()='Tab']/../..\")\n",
    "        chords_table = tree.xpath(\"//td/b[./text()='Chords']/../..\")\n",
    "\n",
    "        for song in tab_table:\n",
    "            name = song.xpath('./td[1]/a[1]')[0].text    \n",
    "            link = song.xpath('./td[1]/a[1]')[0].attrib['href']\n",
    "\n",
    "            if not song.xpath('./td[2]/span[1]'):\n",
    "                rating = 0\n",
    "            else:\n",
    "                rating = song.xpath('./td[2]/span[1]')[0].attrib['title']\n",
    "\n",
    "            all_tabs_chords.append(\n",
    "                {\n",
    "                    'name': name,\n",
    "                    'link': link,\n",
    "                    'rating': rating,\n",
    "                    'type': 'Tab'\n",
    "                }\n",
    "            )\n",
    "            \n",
    "        for song in chords_table:\n",
    "            name = song.xpath('./td[1]/a[1]')[0].text    \n",
    "            link = song.xpath('./td[1]/a[1]')[0].attrib['href']\n",
    "\n",
    "            if not song.xpath('./td[2]/span[1]'):\n",
    "                rating = 0\n",
    "            else:\n",
    "                rating = song.xpath('./td[2]/span[1]')[0].attrib['title']\n",
    "\n",
    "            all_tabs_chords.append(\n",
    "                {\n",
    "                    'name': name,\n",
    "                    'link': link,\n",
    "                    'rating': rating,\n",
    "                    'type': 'Chords'\n",
    "                }\n",
    "            )        \n",
    "        cnt += 1\n",
    "        \n",
    "    return all_tabs_chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_print_version(url):\n",
    "    tries = 0\n",
    "    while tries < 5:\n",
    "        try:\n",
    "            response = urllib.request.urlopen(url)\n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 404:\n",
    "                return None\n",
    "            else:\n",
    "                tries += 1\n",
    "                continue\n",
    "                \n",
    "        htmlparser = etree.HTMLParser()\n",
    "        tree = etree.parse(response, htmlparser)\n",
    "        \n",
    "        # get link\n",
    "        link = tree.xpath(\"//*[@id='print_link']\")[0].attrib['href']\n",
    "        response = urllib.request.urlopen('https://tabs.ultimate-guitar.com{}'.format(link))\n",
    "        \n",
    "        ht = lxml.html.parse(response)\n",
    "        return ht.xpath(\"//div[contains(@class, 'tb_ct')]\")[0].text_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some examples of how the functions work, and what they return, should be self explanatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "band_urls = get_band_urls('w')\n",
    "band_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "artist_links = get_artist_links('/tabs/we_are_scientists_tabs.htm')\n",
    "artist_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab = get_print_version('https://tabs.ultimate-guitar.com/w/we_are_scientists/lethal_enforcer_acoustic_crd.htm')\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is pretty much Pseudo Code. Nothing works yet.\n",
    "\n",
    "This is the outline of the process of crawling the ENTIRE site. UG WILL BLOCK YOU IF YOU TRY THIS.\n",
    "\n",
    "This needs some logic to filter out the top rated tabs/chords for everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_the_stuff = {}\n",
    "\n",
    "for c in chars:\n",
    "    # rip the band urls\n",
    "    band_urls = get_band_urls(c)\n",
    "    \n",
    "    # rip the tabs for each band\n",
    "    for artist, url in band_urls.items():\n",
    "        \n",
    "        all_the_stuff[artist] = {}\n",
    "        \n",
    "        # rip\n",
    "        print('Crawling {}...'.format(artist))\n",
    "        song_links = get_artist_links(url)\n",
    "        \n",
    "        # process\n",
    "        for song_dict in song_links:\n",
    "            entry_name = '{} | {}'.format(song_dict['name'], song_dict['type'])\n",
    "            all_the_stuff[artist][entry_name] = get_print_version(song_dict['link'])\n",
    "\n",
    "        \n",
    "\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
